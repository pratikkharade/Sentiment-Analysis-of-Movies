{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0fb4735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "56fc788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data//roberta//roberta.train.csv')\n",
    "train_x = train.iloc[:,:-1]\n",
    "train_y = train.iloc[:,-1:]\n",
    "\n",
    "train_tfidf = pd.read_csv('data//tfidf//tfidf.train.csv')\n",
    "train_x_tfidf = train_tfidf.iloc[:,:-1]\n",
    "train_y_tfidf = train_tfidf.iloc[:,-1:]\n",
    "\n",
    "test = pd.read_csv('data//roberta//roberta.test.csv')\n",
    "test_x = test.iloc[:,:-1]\n",
    "test_y = test.iloc[:,-1:]\n",
    "\n",
    "test_tfidf = pd.read_csv('data//tfidf//tfidf.test.csv')\n",
    "test_x_tfidf = test_tfidf.iloc[:,:-1]\n",
    "test_y_tfidf = test_tfidf.iloc[:,-1:]\n",
    "\n",
    "eval_df = pd.read_csv('data//roberta//roberta.eval.anon.csv')\n",
    "eval_df = eval_df.iloc[:,:-1]\n",
    "\n",
    "eval_df_tfidf = pd.read_csv('data//tfidf//tfidf.eval.anon.csv')\n",
    "eval_df_tfidf = eval_df_tfidf.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec449cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y.replace(0, -1)\n",
    "train_y_tfidf = train_y_tfidf.replace(0, -1)\n",
    "test_y = test_y.replace(0, -1)\n",
    "test_y_tfidf = test_y_tfidf.replace(0, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "89ae44ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_x.shape[1]):\n",
    "    col = train_x.columns[i]\n",
    "    train_x.rename(columns = {col:'roberta_'+col}, inplace = True)\n",
    "\n",
    "for i in range(train_x_tfidf.shape[1]):\n",
    "    col = train_x_tfidf.columns[i]\n",
    "    train_x_tfidf.rename(columns = {col:'tfidf_'+col}, inplace = True)\n",
    "\n",
    "for i in range(test_x.shape[1]):\n",
    "    col = test_x.columns[i]\n",
    "    test_x.rename(columns = {col:'roberta_'+col}, inplace = True)\n",
    "\n",
    "for i in range(test_x_tfidf.shape[1]):\n",
    "    col = test_x_tfidf.columns[i]\n",
    "    test_x_tfidf.rename(columns = {col:'tfidf_'+col}, inplace = True)\n",
    "\n",
    "for i in range(eval_df.shape[1]):\n",
    "    col = eval_df.columns[i]\n",
    "    eval_df.rename(columns = {col:'roberta_'+col}, inplace = True)\n",
    "\n",
    "for i in range(eval_df_tfidf.shape[1]):\n",
    "    col = eval_df_tfidf.columns[i]\n",
    "    eval_df_tfidf.rename(columns = {col:'tfidf_'+col}, inplace = True)\n",
    "\n",
    "col = train_x_tfidf[train_x_tfidf.columns]\n",
    "train_x = train_x.join(col)\n",
    "\n",
    "col = test_x_tfidf[test_x_tfidf.columns]\n",
    "test_x = test_x.join(col)\n",
    "\n",
    "col = eval_df_tfidf[eval_df_tfidf.columns]\n",
    "eval_df = eval_df.join(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3a3c9747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(x, y, w, b):\n",
    "    pred = np.dot(w.transpose(), x) + b\n",
    "    if (pred > 0 and y == 1) or (pred < 0 and y == -1):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def accuracy(feature_df, label_df, w, b):\n",
    "    size = feature_df.shape[0]\n",
    "    count = 0\n",
    "    for i in range(size):\n",
    "        x = feature_df.iloc[i].tolist()\n",
    "        y = label_df.iloc[i].tolist()[0]\n",
    "        if prediction(x, y, w, b):\n",
    "            count += 1\n",
    "    return (count/size)\n",
    "\n",
    "def prediction_value(x, w, b):\n",
    "    pred = np.dot(w.transpose(), x) + b\n",
    "    if pred > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_predicted_list(feature_df, w, b):\n",
    "    pred_list = []\n",
    "    size = feature_df.shape[0]\n",
    "    count = 0\n",
    "    for i in range(size):\n",
    "        x = feature_df.iloc[i].tolist()\n",
    "        pred_list.append(prediction_value(x, w, b))\n",
    "    return pred_list\n",
    "\n",
    "def generate_w_b(size):\n",
    "    np.random.seed(65)\n",
    "    w = np.array(np.random.normal(-0.01, 0.01, size))\n",
    "    b = np.random.normal(-0.01, 0.01)\n",
    "    w_a = w\n",
    "    b_a = b\n",
    "    return w, b, w_a, b_a\n",
    "\n",
    "def update_w_b(x, y, w, b, w_a, b_a, lr, update_count):\n",
    "    eq = y*(np.dot(w.transpose(), x) + b)\n",
    "    x = np.array(x)\n",
    "    if eq < 0:\n",
    "        w = w + lr*y*x\n",
    "        b = b + lr*y\n",
    "        update_count += 1\n",
    "    w_a = w_a + w\n",
    "    b_a = b_a + b\n",
    "    return w, b, w_a, b_a, update_count\n",
    "\n",
    "def perceptron(features, labels, w, b, w_a, b_a, lr, epochs, dev=False, test_df_x=None, test_df_y=None):\n",
    "    w_list = []\n",
    "    b_list = []\n",
    "    update_count = 0\n",
    "    accuracies_list = []\n",
    "    index_list = np.arange(features.shape[0])\n",
    "    for e in range(epochs):\n",
    "        print(\"epoch:\", e)\n",
    "        np.random.seed(e)\n",
    "        np.random.shuffle(index_list)\n",
    "        for i in index_list:\n",
    "            x = features.iloc[i].tolist()\n",
    "            y = labels.iloc[i].tolist()[0]\n",
    "            w, b, w_a, b_a, update_count = update_w_b(x, y, w, b, w_a, b_a, lr, update_count)\n",
    "        if dev:\n",
    "            b_list.append(b_a)\n",
    "            w_list.append(w_a.copy())\n",
    "            acc = accuracy(test_df_x, test_df_y, w_a, b_a)\n",
    "            accuracies_list.append(acc)\n",
    "            print(\"Developmental dataset accuracy for epoch\", e, \"=\", acc)\n",
    "    if dev:\n",
    "        return w, b, w_a, b_a, accuracies_list, update_count, w_list, b_list\n",
    "    else:\n",
    "        return w, b, w_a, b_a, update_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "87ea274c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 1\n",
      "epoch: 0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "epoch: 3\n",
      "epoch: 4\n",
      "epoch: 5\n",
      "epoch: 6\n",
      "epoch: 7\n",
      "epoch: 8\n",
      "epoch: 9\n",
      "epoch: 10\n",
      "epoch: 11\n",
      "epoch: 12\n",
      "epoch: 13\n",
      "epoch: 14\n",
      "epoch: 15\n",
      "epoch: 16\n",
      "epoch: 17\n",
      "epoch: 18\n",
      "epoch: 19\n",
      "lr: 0.1\n",
      "epoch: 0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "epoch: 3\n",
      "epoch: 4\n",
      "epoch: 5\n",
      "epoch: 6\n",
      "epoch: 7\n",
      "epoch: 8\n",
      "epoch: 9\n",
      "epoch: 10\n",
      "epoch: 11\n",
      "epoch: 12\n",
      "epoch: 13\n",
      "epoch: 14\n",
      "epoch: 15\n",
      "epoch: 16\n",
      "epoch: 17\n",
      "epoch: 18\n",
      "epoch: 19\n",
      "lr: 0.01\n",
      "epoch: 0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "epoch: 3\n",
      "epoch: 4\n",
      "epoch: 5\n",
      "epoch: 6\n",
      "epoch: 7\n",
      "epoch: 8\n",
      "epoch: 9\n",
      "epoch: 10\n",
      "epoch: 11\n",
      "epoch: 12\n",
      "epoch: 13\n",
      "epoch: 14\n",
      "epoch: 15\n",
      "epoch: 16\n",
      "epoch: 17\n",
      "epoch: 18\n",
      "epoch: 19\n",
      "{1: 0.8272214386459803, 0.1: 0.8265162200282088, 0.01: 0.8300423131170663}\n"
     ]
    }
   ],
   "source": [
    "#CROSS VALIDATION\n",
    "k = 5\n",
    "epochs = 20\n",
    "lrs = [1, 0.1, 0.01]\n",
    "\n",
    "train_length = int(train_x.shape[0]*4//5)\n",
    "test_length = train_x.shape[0] - train_length\n",
    "\n",
    "train_x_fold = train_x.head(train_length)\n",
    "train_y_fold = train_y.head(train_length)\n",
    "\n",
    "test_x_fold = train_x.tail(test_length)\n",
    "test_y_fold = train_y.tail(test_length)\n",
    "\n",
    "accuracies = {}\n",
    "\n",
    "for lr in lrs:\n",
    "    print(\"lr:\", lr)\n",
    "    w, b, w_a, b_a = generate_w_b(train_x.shape[1])\n",
    "    w, b, w_a, b_a, update_count = perceptron(train_x_fold, train_y_fold, w, b, w_a, b_a, lr, epochs)\n",
    "    acc = accuracy(test_x_fold, test_y_fold, w_a, b_a)\n",
    "    accuracies[lr] = acc\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9bc0e7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LR: 0.01\n",
      "epoch: 0\n",
      "Developmental dataset accuracy for epoch 0 = 0.5437235543018336\n",
      "epoch: 1\n",
      "Developmental dataset accuracy for epoch 1 = 0.8067700987306065\n",
      "epoch: 2\n",
      "Developmental dataset accuracy for epoch 2 = 0.8166431593794076\n",
      "epoch: 3\n",
      "Developmental dataset accuracy for epoch 3 = 0.8201692524682651\n",
      "epoch: 4\n",
      "Developmental dataset accuracy for epoch 4 = 0.8229901269393513\n",
      "epoch: 5\n",
      "Developmental dataset accuracy for epoch 5 = 0.8279266572637518\n",
      "epoch: 6\n",
      "Developmental dataset accuracy for epoch 6 = 0.8321579689703809\n",
      "epoch: 7\n",
      "Developmental dataset accuracy for epoch 7 = 0.8363892806770099\n",
      "epoch: 8\n",
      "Developmental dataset accuracy for epoch 8 = 0.840620592383639\n",
      "epoch: 9\n",
      "Developmental dataset accuracy for epoch 9 = 0.842031029619182\n",
      "epoch: 10\n",
      "Developmental dataset accuracy for epoch 10 = 0.843441466854725\n",
      "epoch: 11\n",
      "Developmental dataset accuracy for epoch 11 = 0.847672778561354\n",
      "epoch: 12\n",
      "Developmental dataset accuracy for epoch 12 = 0.8519040902679831\n",
      "epoch: 13\n",
      "Developmental dataset accuracy for epoch 13 = 0.8533145275035261\n",
      "epoch: 14\n",
      "Developmental dataset accuracy for epoch 14 = 0.8561354019746121\n",
      "epoch: 15\n",
      "Developmental dataset accuracy for epoch 15 = 0.8561354019746121\n",
      "epoch: 16\n",
      "Developmental dataset accuracy for epoch 16 = 0.8575458392101551\n",
      "epoch: 17\n",
      "Developmental dataset accuracy for epoch 17 = 0.8610719322990127\n",
      "epoch: 18\n",
      "Developmental dataset accuracy for epoch 18 = 0.8596614950634697\n",
      "epoch: 19\n",
      "Developmental dataset accuracy for epoch 19 = 0.8603667136812412\n",
      "\n",
      "Total number of updates on training set: 45087\n",
      "Max accuracy in developmental dataset: 0.8610719322990127\n",
      "Max accuracy in developmental dataset was found at epoch number: 17\n",
      "Train accuracy with w and b corresponding to best accuracy for dev dataset = 0.8511568848758465\n",
      "Test accuracy with w and b corresponding to best accuracy for dev dataset = 0.804476629361422\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_lr = max(accuracies, key = lambda x: accuracies[x])\n",
    "lr = best_lr\n",
    "print(\"Best LR:\", lr)\n",
    "epochs = 20\n",
    "\n",
    "w, b, w_a, b_a = generate_w_b(train_x.shape[1])\n",
    "w, b, w_a, b_a, accuracies_list, update_count, w_list, b_list = perceptron(train_x, train_y, w, b, w_a, b_a, lr, epochs, True, test_x_fold, test_y_fold)\n",
    "\n",
    "print()\n",
    "print(\"Total number of updates on training set:\", update_count)\n",
    "print(\"Max accuracy in developmental dataset:\", max(accuracies_list))\n",
    "index = accuracies_list.index(max(accuracies_list))\n",
    "print(\"Max accuracy in developmental dataset was found at epoch number:\", index)\n",
    "best_w = w_list[index]\n",
    "best_b = b_list[index]\n",
    "print(\"Train accuracy with w and b corresponding to best accuracy for dev dataset =\", accuracy(train_x, train_y, best_w, best_b))\n",
    "print(\"Test accuracy with w and b corresponding to best accuracy for dev dataset =\", accuracy(test_x, test_y, best_w, best_b))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95e39142",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = get_predicted_list(eval_df, best_w, best_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "877937a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('1_avgPerceptron_roberta_tfidf_65s_20e.csv', 'w', newline ='')\n",
    "\n",
    "with file:\n",
    "    header = ['example_id', 'label']\n",
    "    writer = csv.DictWriter(file, fieldnames = header)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for i in range(len(pred)):\n",
    "        writer.writerow({'example_id' : i, 'label': pred[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea90f79f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
